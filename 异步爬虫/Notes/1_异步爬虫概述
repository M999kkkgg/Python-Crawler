高性能异步爬虫
    - 在爬虫中使用异步实现高性能的数据爬取操作
    - 单线程且串行效率低
        # 只能等到一个URL响应结束之后
        # 才能进行下面的URL爬取
        # get方法是一个阻塞的方法
    - 异步爬虫的方式
        # 多线程，多进程（不建议）
            * 可以为相关阻塞的操作单独开启线程或者进程
            * 阻塞操作就可以异步执行
            * 无法无限制地开启多线程或者多进程
        # 线程池，进程池（适当使用）
            * 降低系统对进程或者线程创建/销毁的频率，从而很好的降低系统开销
            * 池中线程或进程的数量是有上限的
            * 阻塞操作远远高于池中上限时，效率提升不明显
        # 单线程+异步协程（推荐）

线程池的使用
    - 见TestPackPage.TestThread.py
    - from multiprocessing import Pool
    - 实例化Pool对象（参数表示开辟的线程数目）
    - 使用map方法
        # 参数func表示阻塞的函数
        # 参数iterable表示函数的参数
            * 一个传参时较简单
            * 多个传参时用关键字传参一一对应
            * 并且重构阻塞函数
        # 返回的参数为列表
    - 调用map后记得关闭线程池
        # pool.close()
    - 主线程在子线程结束后再结束
        # pool.join()

单线程+异步协程
    - event_loop: 事件循环
        # 相当于无限循环，我们可以把一些函数注册到这个事件循环上
        # 当满足某些条件时，函数就会被循环执行
    - coroutine: 协程对象
        # 我们可以将协程对象注册到事件循环中，他会被事件循环调用
        # 我们可以使用async关键字来定义一个方法，这个方法在调用时不会被立刻执行
        # 而是返回一个协程对象
    - task: 任务
        # 它是对协程对象的进一步封装，包含了任务的各个状态
    - future
        # 代表将来执行还没有执行的任务，实际上和task没有本质区别
    - async
        # 定义一个协程
    - await
        # 用起来挂起阻塞方法的执行